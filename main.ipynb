{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from serverbase import *\n",
    "from userbase import *\n",
    "from serverDoVeRA import *\n",
    "from userDoVeRA import *\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "config = {\n",
    "        \"num_user\": 3,\n",
    "        \"batch_size\": 64,\n",
    "        \"global_L\": True,\n",
    "        \"dim_L\": 2,\n",
    "        \"num_gpus\": num_gpus,\n",
    "        \"global_epochs\": 20,\n",
    "        \"user_ratio\": 1}\n",
    "\n",
    "num_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([640, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([640])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import  datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 640\n",
    "\n",
    "train_dataset = datasets.MNIST(root='data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='data', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_client = 3\n",
    "clients = []\n",
    "\n",
    "server = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torch.utils.data.dataloader.DataLoader at 0x7f5d141b37c0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f5d141b3eb0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f5bf1497760>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader_list = []\n",
    "\n",
    "labels = [0, 1, 2]\n",
    "indices = [idx for idx, target in enumerate(train_dataset.targets) if target in labels]\n",
    "dataloader = torch.utils.data.DataLoader(torch.utils.data.Subset(train_dataset, indices),\n",
    "                                         batch_size=BATCH_SIZE)\n",
    "train_loader_list.append(dataloader)\n",
    "labels = [3, 4, 5]\n",
    "indices = [idx for idx, target in enumerate(train_dataset.targets) if target in labels]\n",
    "dataloader = torch.utils.data.DataLoader(torch.utils.data.Subset(train_dataset, indices),\n",
    "                                         batch_size=BATCH_SIZE)\n",
    "train_loader_list.append(dataloader)\n",
    "labels = [6, 7, 8, 9]\n",
    "indices = [idx for idx, target in enumerate(train_dataset.targets) if target in labels]\n",
    "dataloader = torch.utils.data.DataLoader(torch.utils.data.Subset(train_dataset, indices),\n",
    "                                         batch_size=BATCH_SIZE)\n",
    "train_loader_list.append(dataloader)\n",
    "\n",
    "train_loader_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, num_features, num_hidden_1, num_hidden_2, num_classes):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(num_features, num_hidden_1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden_1, num_hidden_2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden_2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 28*28\n",
    "num_hidden_1 = 128\n",
    "num_hidden_2 = 256\n",
    "num_classes = 10\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "learning_rate = 0.005\n",
    "num_epoches = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "    # model.eval()\n",
    "    correct_pred, num_examples = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, targets in data_loader:\n",
    "            features = features.view(-1, 28*28).to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            logits = model(features)\n",
    "            _, predicted_labels = torch.max(logits, 1)\n",
    "            num_examples += targets.size(0)\n",
    "            correct_pred += (predicted_labels==targets).sum()\n",
    "\n",
    "        return correct_pred.float()/num_examples*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "MultiLayerPerceptron(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "model = MultiLayerPerceptron(\n",
    "    num_features=num_features,\n",
    "    num_hidden_1=num_hidden_1,\n",
    "    num_hidden_2=num_hidden_2,\n",
    "    num_classes=num_classes\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "optimizer_pretrained = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(device)\n",
    "print(model)\n",
    "print(optimizer_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch.nn.functional as F\n",
    "def train(num_epoches, model, optimizer, train_loader, device):\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epoches):\n",
    "        for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "            features = features.view(-1, 28*28).to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            logits = model(features)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if not batch_idx%400:\n",
    "                print('Epoch: %03d/%03d|Batch %03d/%03d| Loss: %.4f' % (epoch+1, num_epoches, batch_idx, len(train_loader), loss))\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            print('Epoch: %03d/%03d training accuracy: %.2f%%' % (epoch+1, num_epoches, compute_accuracy(model, train_loader, device)))\n",
    "\n",
    "        print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "    print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/005|Batch 000/094| Loss: 2.3053\n",
      "Epoch: 001/005 training accuracy: 95.21%\n",
      "Time elapsed: 0.11 min\n",
      "Epoch: 002/005|Batch 000/094| Loss: 0.1342\n",
      "Epoch: 002/005 training accuracy: 97.14%\n",
      "Time elapsed: 0.22 min\n",
      "Epoch: 003/005|Batch 000/094| Loss: 0.1267\n",
      "Epoch: 003/005 training accuracy: 97.42%\n",
      "Time elapsed: 0.33 min\n",
      "Epoch: 004/005|Batch 000/094| Loss: 0.0813\n",
      "Epoch: 004/005 training accuracy: 98.35%\n",
      "Time elapsed: 0.43 min\n",
      "Epoch: 005/005|Batch 000/094| Loss: 0.0412\n",
      "Epoch: 005/005 training accuracy: 98.80%\n",
      "Time elapsed: 0.54 min\n",
      "Total Training Time: 0.54 min\n",
      "Test accuracy: 97.49%\n"
     ]
    }
   ],
   "source": [
    "train(num_epoches, model, optimizer_pretrained, train_loader, device)\n",
    "print(f'Test accuracy: {compute_accuracy(model, test_loader, device):.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fed MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "server_model = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "val_loss: 0.07399697927758098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   5%|▌         | 1/20 [00:21<06:49, 21.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.8499984741211%\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "val_loss: 0.07547288434579968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  10%|█         | 2/20 [00:41<06:10, 20.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.79999542236328%\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "val_loss: 0.08223380986601114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  15%|█▌        | 3/20 [01:01<05:44, 20.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.61000061035156%\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "val_loss: 0.08928364282473922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  20%|██        | 4/20 [01:21<05:22, 20.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.40999603271484%\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "val_loss: 0.09891076711937785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  25%|██▌       | 5/20 [01:41<05:01, 20.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.0999984741211%\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "val_loss: 0.0993972725700587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  30%|███       | 6/20 [02:01<04:42, 20.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.19000244140625%\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "val_loss: 0.1102590449154377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  35%|███▌      | 7/20 [02:21<04:21, 20.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 96.97000122070312%\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "val_loss: 0.1121402932330966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  40%|████      | 8/20 [02:41<04:00, 20.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 96.87000274658203%\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "val_loss: 0.12939141085371375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  45%|████▌     | 9/20 [03:01<03:40, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 96.59000396728516%\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "val_loss: 0.1322789746336639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  50%|█████     | 10/20 [03:21<03:19, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 96.43000030517578%\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "val_loss: 0.13430627342313528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  55%|█████▌    | 11/20 [03:41<02:59, 19.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 96.44000244140625%\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "val_loss: 0.13616208778694272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  60%|██████    | 12/20 [04:01<02:39, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 96.62999725341797%\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "val_loss: 0.14684918895363808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  65%|██████▌   | 13/20 [04:21<02:19, 19.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 96.4000015258789%\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "val_loss: 0.13582701445557177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  70%|███████   | 14/20 [04:41<01:59, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 96.70999908447266%\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "val_loss: 0.16833082539960742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  75%|███████▌  | 15/20 [05:00<01:39, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 96.15999603271484%\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "val_loss: 0.14374617487192154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  80%|████████  | 16/20 [05:20<01:19, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 96.63999938964844%\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "val_loss: 0.151554049924016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  85%|████████▌ | 17/20 [05:41<01:00, 20.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 96.52999877929688%\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "val_loss: 0.15025727823376656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  90%|█████████ | 18/20 [06:01<00:40, 20.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 96.51000213623047%\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "val_loss: 0.18111255392432213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  95%|█████████▌| 19/20 [06:22<00:20, 20.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 96.01000213623047%\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.2.weight\n",
      "layers.2.bias\n",
      "layers.4.weight\n",
      "layers.4.bias\n",
      "val_loss: 0.16727013047784567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 20/20 [06:41<00:00, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 96.48999786376953%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "server = ServerMLP(model=server_model, test_loader=test_loader)\n",
    "\n",
    "user_list = []\n",
    "\n",
    "# Create users\n",
    "for i in range(3):\n",
    "    user_i = UserMLP(train_loader=train_loader_list[i], model=server_model, user_id=i, local_epochs=5)\n",
    "    user_list.append(user_i)\n",
    "\n",
    "\n",
    "\n",
    "for _ in tqdm(range(20), desc=f\"Progress\"):\n",
    "    # Distribute initial model to users\n",
    "    server.distribute_model(user_list)\n",
    "    \n",
    "    # Sub-sample users\n",
    "    sub_user_list = random.sample(user_list, int(1 * 3))\n",
    "\n",
    "    # Check the sub-sampled user and train model\n",
    "    users_loss = 0.0\n",
    "    for user in sub_user_list:\n",
    "        user_loss = user.user_train()\n",
    "        users_loss += user_loss\n",
    "    # Aggregate weights on server\n",
    "    server.aggregate_weights(sub_user_list)\n",
    "\n",
    "    # Calulate avg loss on selected users\n",
    "    train_loss =  users_loss / len(sub_user_list)    \n",
    "    val_loss = server.model_eval()\n",
    "\n",
    "    # wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss})\n",
    "    print(f'Test accuracy of server: {server.compute_accuracy()}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_linear_layers(model):\n",
    "    for child in model.children():\n",
    "        if isinstance(child, nn.Linear):\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad=False\n",
    "        else:\n",
    "            freeze_linear_layers(child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRALayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
    "        super().__init__()\n",
    "        std_dev = 1/torch.sqrt(torch.tensor(rank).float())\n",
    "        self.A = nn.Parameter(torch.randn(in_dim, rank)*std_dev)\n",
    "        self.B = nn.Parameter(torch.zeros(rank, out_dim))\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.alpha*(x@self.A@self.B)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "class LinearWithLoRAMerged(nn.Module):\n",
    "    def __init__(self, linear, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.linear = linear\n",
    "        self.lora = LoRALayer(\n",
    "            linear.in_features,\n",
    "            linear.out_features,\n",
    "            rank,\n",
    "            alpha\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        lora = self.lora.A @ self.lora.B\n",
    "        combined_weight = self.linear.weight+self.lora.alpha*lora.T\n",
    "\n",
    "        return F.linear(x, combined_weight, self.linear.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayerPerceptron(\n",
      "  (layers): Sequential(\n",
      "    (0): LinearWithLoRAMerged(\n",
      "      (linear): Linear(in_features=784, out_features=128, bias=True)\n",
      "      (lora): LoRALayer()\n",
      "    )\n",
      "    (1): ReLU()\n",
      "    (2): LinearWithLoRAMerged(\n",
      "      (linear): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (lora): LoRALayer()\n",
      "    )\n",
      "    (3): ReLU()\n",
      "    (4): LinearWithLoRAMerged(\n",
      "      (linear): Linear(in_features=256, out_features=10, bias=True)\n",
      "      (lora): LoRALayer()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "model_lora = copy.deepcopy(model)\n",
    "\n",
    "model_lora.layers[0]=LinearWithLoRAMerged(model_lora.layers[0], rank=4, alpha=8)\n",
    "model_lora.layers[2]=LinearWithLoRAMerged(model_lora.layers[2], rank=4, alpha=8)\n",
    "model_lora.layers[4]=LinearWithLoRAMerged(model_lora.layers[4], rank=4, alpha=8)\n",
    "model_lora.to(device)\n",
    "optimizer_lora=torch.optim.Adam(model_lora.parameters(), lr=learning_rate)\n",
    "print(model_lora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.linear.weight: False\n",
      "layers.0.linear.bias: False\n",
      "layers.0.lora.A: True\n",
      "layers.0.lora.B: True\n",
      "layers.2.linear.weight: False\n",
      "layers.2.linear.bias: False\n",
      "layers.2.lora.A: True\n",
      "layers.2.lora.B: True\n",
      "layers.4.linear.weight: False\n",
      "layers.4.linear.bias: False\n",
      "layers.4.lora.A: True\n",
      "layers.4.lora.B: True\n"
     ]
    }
   ],
   "source": [
    "freeze_linear_layers(model_lora)\n",
    "for name, param in model_lora.named_parameters():\n",
    "    print(f'{name}: {param.requires_grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.linear.weight\n",
      "layers.0.linear.bias\n",
      "layers.0.lora.A\n",
      "layers.0.lora.B\n",
      "layers.2.linear.weight\n",
      "layers.2.linear.bias\n",
      "layers.2.lora.A\n",
      "layers.2.lora.B\n",
      "layers.4.linear.weight\n",
      "layers.4.linear.bias\n",
      "layers.4.lora.A\n",
      "layers.4.lora.B\n",
      "layers.0.linear.weight\n",
      "layers.0.linear.bias\n",
      "layers.0.lora.A\n",
      "layers.0.lora.B\n",
      "layers.2.linear.weight\n",
      "layers.2.linear.bias\n",
      "layers.2.lora.A\n",
      "layers.2.lora.B\n",
      "layers.4.linear.weight\n",
      "layers.4.linear.bias\n",
      "layers.4.lora.A\n",
      "layers.4.lora.B\n",
      "layers.0.linear.weight\n",
      "layers.0.linear.bias\n",
      "layers.0.lora.A\n",
      "layers.0.lora.B\n",
      "layers.2.linear.weight\n",
      "layers.2.linear.bias\n",
      "layers.2.lora.A\n",
      "layers.2.lora.B\n",
      "layers.4.linear.weight\n",
      "layers.4.linear.bias\n",
      "layers.4.lora.A\n",
      "layers.4.lora.B\n",
      "val_loss: 0.08553802664391696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   5%|▌         | 1/20 [00:21<06:43, 21.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.31999969482422%\n",
      "layers.0.linear.weight\n",
      "layers.0.linear.bias\n",
      "layers.0.lora.A\n",
      "layers.0.lora.B\n",
      "layers.2.linear.weight\n",
      "layers.2.linear.bias\n",
      "layers.2.lora.A\n",
      "layers.2.lora.B\n",
      "layers.4.linear.weight\n",
      "layers.4.linear.bias\n",
      "layers.4.lora.A\n",
      "layers.4.lora.B\n",
      "layers.0.linear.weight\n",
      "layers.0.linear.bias\n",
      "layers.0.lora.A\n",
      "layers.0.lora.B\n",
      "layers.2.linear.weight\n",
      "layers.2.linear.bias\n",
      "layers.2.lora.A\n",
      "layers.2.lora.B\n",
      "layers.4.linear.weight\n",
      "layers.4.linear.bias\n",
      "layers.4.lora.A\n",
      "layers.4.lora.B\n",
      "layers.0.linear.weight\n",
      "layers.0.linear.bias\n",
      "layers.0.lora.A\n",
      "layers.0.lora.B\n",
      "layers.2.linear.weight\n",
      "layers.2.linear.bias\n",
      "layers.2.lora.A\n",
      "layers.2.lora.B\n",
      "layers.4.linear.weight\n",
      "layers.4.linear.bias\n",
      "layers.4.lora.A\n",
      "layers.4.lora.B\n",
      "val_loss: 0.08775392640382051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  10%|█         | 2/20 [00:42<06:18, 21.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.39999389648438%\n",
      "layers.0.linear.weight\n",
      "layers.0.linear.bias\n",
      "layers.0.lora.A\n",
      "layers.0.lora.B\n",
      "layers.2.linear.weight\n",
      "layers.2.linear.bias\n",
      "layers.2.lora.A\n",
      "layers.2.lora.B\n",
      "layers.4.linear.weight\n",
      "layers.4.linear.bias\n",
      "layers.4.lora.A\n",
      "layers.4.lora.B\n",
      "layers.0.linear.weight\n",
      "layers.0.linear.bias\n",
      "layers.0.lora.A\n",
      "layers.0.lora.B\n",
      "layers.2.linear.weight\n",
      "layers.2.linear.bias\n",
      "layers.2.lora.A\n",
      "layers.2.lora.B\n",
      "layers.4.linear.weight\n",
      "layers.4.linear.bias\n",
      "layers.4.lora.A\n",
      "layers.4.lora.B\n",
      "layers.0.linear.weight\n",
      "layers.0.linear.bias\n",
      "layers.0.lora.A\n",
      "layers.0.lora.B\n",
      "layers.2.linear.weight\n",
      "layers.2.linear.bias\n",
      "layers.2.lora.A\n",
      "layers.2.lora.B\n",
      "layers.4.linear.weight\n",
      "layers.4.linear.bias\n",
      "layers.4.lora.A\n",
      "layers.4.lora.B\n",
      "val_loss: 0.09048473229631782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  15%|█▌        | 3/20 [01:03<05:58, 21.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.16999816894531%\n",
      "layers.0.linear.weight\n",
      "layers.0.linear.bias\n",
      "layers.0.lora.A\n",
      "layers.0.lora.B\n",
      "layers.2.linear.weight\n",
      "layers.2.linear.bias\n",
      "layers.2.lora.A\n",
      "layers.2.lora.B\n",
      "layers.4.linear.weight\n",
      "layers.4.linear.bias\n",
      "layers.4.lora.A\n",
      "layers.4.lora.B\n",
      "layers.0.linear.weight\n",
      "layers.0.linear.bias\n",
      "layers.0.lora.A\n",
      "layers.0.lora.B\n",
      "layers.2.linear.weight\n",
      "layers.2.linear.bias\n",
      "layers.2.lora.A\n",
      "layers.2.lora.B\n",
      "layers.4.linear.weight\n",
      "layers.4.linear.bias\n",
      "layers.4.lora.A\n",
      "layers.4.lora.B\n",
      "layers.0.linear.weight\n",
      "layers.0.linear.bias\n",
      "layers.0.lora.A\n",
      "layers.0.lora.B\n",
      "layers.2.linear.weight\n",
      "layers.2.linear.bias\n",
      "layers.2.lora.A\n",
      "layers.2.lora.B\n",
      "layers.4.linear.weight\n",
      "layers.4.linear.bias\n",
      "layers.4.lora.A\n",
      "layers.4.lora.B\n",
      "val_loss: 0.09238581359386444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  20%|██        | 4/20 [01:24<05:37, 21.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.16999816894531%\n",
      "layers.0.linear.weight\n",
      "layers.0.linear.bias\n",
      "layers.0.lora.A\n",
      "layers.0.lora.B\n",
      "layers.2.linear.weight\n",
      "layers.2.linear.bias\n",
      "layers.2.lora.A\n",
      "layers.2.lora.B\n",
      "layers.4.linear.weight\n",
      "layers.4.linear.bias\n",
      "layers.4.lora.A\n",
      "layers.4.lora.B\n",
      "layers.0.linear.weight\n",
      "layers.0.linear.bias\n",
      "layers.0.lora.A\n",
      "layers.0.lora.B\n",
      "layers.2.linear.weight\n",
      "layers.2.linear.bias\n",
      "layers.2.lora.A\n",
      "layers.2.lora.B\n",
      "layers.4.linear.weight\n",
      "layers.4.linear.bias\n",
      "layers.4.lora.A\n",
      "layers.4.lora.B\n",
      "layers.0.linear.weight\n",
      "layers.0.linear.bias\n",
      "layers.0.lora.A\n",
      "layers.0.lora.B\n",
      "layers.2.linear.weight\n",
      "layers.2.linear.bias\n",
      "layers.2.lora.A\n",
      "layers.2.lora.B\n",
      "layers.4.linear.weight\n",
      "layers.4.linear.bias\n",
      "layers.4.lora.A\n",
      "layers.4.lora.B\n",
      "val_loss: 0.09461246151477098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  25%|██▌       | 5/20 [01:45<05:16, 21.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.04000091552734%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  25%|██▌       | 5/20 [01:46<05:18, 21.23s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m users_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user \u001b[38;5;129;01min\u001b[39;00m sub_user_list:\n\u001b[0;32m---> 28\u001b[0m     user_loss \u001b[38;5;241m=\u001b[39m \u001b[43muser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     users_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m user_loss\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Aggregate weights on server\u001b[39;00m\n",
      "File \u001b[0;32m~/quan/lora_test/fed-dovera/userDoVeRA.py:23\u001b[0m, in \u001b[0;36mUserMLP.user_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_epochs):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader:\n\u001b[1;32m     24\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     25\u001b[0m         targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/quan/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/quan/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/quan/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/quan/.venv/lib/python3.10/site-packages/torch/utils/data/dataset.py:399\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/quan/.venv/lib/python3.10/site-packages/torch/utils/data/dataset.py:399\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/quan/.venv/lib/python3.10/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/quan/.venv/lib/python3.10/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/quan/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:171\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    170\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n\u001b[0;32m--> 171\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image_num_channels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[1;32m    173\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "server = ServerMLP(model=model_lora, test_loader=test_loader)\n",
    "\n",
    "user_list = []\n",
    "\n",
    "# Create users\n",
    "for i in range(3):\n",
    "    user_i = UserMLP(train_loader=train_loader_list[i], model=model_lora, user_id=i, local_epochs=5)\n",
    "    user_list.append(user_i)\n",
    "\n",
    "\n",
    "\n",
    "for _ in tqdm(range(20), desc=f\"Progress\"):\n",
    "    # Distribute initial model to users\n",
    "    server.distribute_model(user_list)\n",
    "    \n",
    "    # Sub-sample users\n",
    "    sub_user_list = random.sample(user_list, int(1 * 3))\n",
    "\n",
    "    # Check the sub-sampled user and train model\n",
    "    users_loss = 0.0\n",
    "    for user in sub_user_list:\n",
    "        user_loss = user.user_train()\n",
    "        users_loss += user_loss\n",
    "    # Aggregate weights on server\n",
    "    server.aggregate_weights(sub_user_list)\n",
    "\n",
    "    # Calulate avg loss on selected users\n",
    "    train_loss =  users_loss / len(sub_user_list)    \n",
    "    val_loss = server.model_eval()\n",
    "\n",
    "    # wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss})\n",
    "    print(f'Test accuracy of server: {server.compute_accuracy()}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DoVeRa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VeRALayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
    "        super().__init__()\n",
    "        std_dev = 1/torch.sqrt(torch.tensor(rank).float())\n",
    "        self.A = nn.Parameter(torch.normal(size=(in_dim, rank), mean=0., std=std_dev), requires_grad=False)\n",
    "        self.d = nn.Parameter(torch.ones(rank))\n",
    "        self.B = nn.Parameter(torch.normal(size=(rank, out_dim), mean=0., std=std_dev), requires_grad=False)\n",
    "        self.b = nn.Parameter(torch.zeros(out_dim))\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.alpha * (x @ self.A @ torch.diag(self.d) @ self.B @ torch.diag(self.b))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearWithDoVeRAMerged(nn.Module):\n",
    "    def __init__(self, linear, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.linear = linear\n",
    "        self.vera = VeRALayer(\n",
    "            linear.in_features, linear.out_features, rank, alpha\n",
    "        )\n",
    "        self.m = nn.Parameter(self.linear.weight.norm(p=2, dim=0, keepdim=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        vera=self.vera.A @ torch.diag(self.vera.d) @ self.vera.B @ torch.diag(self.vera.b)\n",
    "        numerator=self.linear.weight+self.vera.alpha*vera.T\n",
    "        denominator=numerator.norm(p=2, dim=0, keepdim=True)\n",
    "        directional_component=numerator/denominator\n",
    "        new_weight=self.m*directional_component\n",
    "        return F.linear(x, new_weight, self.linear.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayerPerceptron(\n",
      "  (layers): Sequential(\n",
      "    (0): LinearWithDoVeRAMerged(\n",
      "      (linear): Linear(in_features=784, out_features=128, bias=True)\n",
      "      (vera): VeRALayer()\n",
      "    )\n",
      "    (1): ReLU()\n",
      "    (2): LinearWithDoVeRAMerged(\n",
      "      (linear): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (vera): VeRALayer()\n",
      "    )\n",
      "    (3): ReLU()\n",
      "    (4): LinearWithDoVeRAMerged(\n",
      "      (linear): Linear(in_features=256, out_features=10, bias=True)\n",
      "      (vera): VeRALayer()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "model_dovera = copy.deepcopy(model)\n",
    "\n",
    "model_dovera.layers[0]=LinearWithDoVeRAMerged(model_dovera.layers[0], rank=4, alpha=8)\n",
    "model_dovera.layers[2]=LinearWithDoVeRAMerged(model_dovera.layers[2], rank=4, alpha=8)\n",
    "model_dovera.layers[4]=LinearWithDoVeRAMerged(model_dovera.layers[4], rank=4, alpha=8)\n",
    "\n",
    "model_dovera.to(device)\n",
    "optimizer_dovera=torch.optim.Adam(model_dovera.parameters(), lr=learning_rate)\n",
    "\n",
    "print(model_dovera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.m: True\n",
      "layers.0.linear.weight: False\n",
      "layers.0.linear.bias: False\n",
      "layers.0.vera.A: False\n",
      "layers.0.vera.d: True\n",
      "layers.0.vera.B: False\n",
      "layers.0.vera.b: True\n",
      "layers.2.m: True\n",
      "layers.2.linear.weight: False\n",
      "layers.2.linear.bias: False\n",
      "layers.2.vera.A: False\n",
      "layers.2.vera.d: True\n",
      "layers.2.vera.B: False\n",
      "layers.2.vera.b: True\n",
      "layers.4.m: True\n",
      "layers.4.linear.weight: False\n",
      "layers.4.linear.bias: False\n",
      "layers.4.vera.A: False\n",
      "layers.4.vera.d: True\n",
      "layers.4.vera.B: False\n",
      "layers.4.vera.b: True\n"
     ]
    }
   ],
   "source": [
    "freeze_linear_layers(model_dovera)\n",
    "for name, param in model_dovera.named_parameters():\n",
    "    print(f'{name}: {param.requires_grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.07653172709979117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   5%|▌         | 1/20 [00:23<07:27, 23.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.80999755859375%\n",
      "val_loss: 0.076780412113294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  10%|█         | 2/20 [00:46<07:01, 23.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.7699966430664%\n",
      "val_loss: 0.07780138798989356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  15%|█▌        | 3/20 [01:10<06:41, 23.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.69999694824219%\n",
      "val_loss: 0.07961395150050521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  20%|██        | 4/20 [01:34<06:18, 23.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.7199935913086%\n",
      "val_loss: 0.08090309845283628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  25%|██▌       | 5/20 [01:59<06:02, 24.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.66999816894531%\n",
      "val_loss: 0.0816525318659842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  30%|███       | 6/20 [02:23<05:35, 23.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.67999267578125%\n",
      "val_loss: 0.08376806182786822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  35%|███▌      | 7/20 [02:46<05:09, 23.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.69999694824219%\n",
      "val_loss: 0.08381795464083552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  40%|████      | 8/20 [03:10<04:44, 23.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.7199935913086%\n",
      "val_loss: 0.08524775435216725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  45%|████▌     | 9/20 [03:34<04:23, 23.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.7199935913086%\n",
      "val_loss: 0.08545513963326812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  50%|█████     | 10/20 [03:59<04:03, 24.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.73999786376953%\n",
      "val_loss: 0.08651515864767134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  55%|█████▌    | 11/20 [04:23<03:38, 24.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.7199935913086%\n",
      "val_loss: 0.08824604540131986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  60%|██████    | 12/20 [04:49<03:17, 24.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.70999908447266%\n",
      "val_loss: 0.0878830412402749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  65%|██████▌   | 13/20 [05:13<02:51, 24.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.68999481201172%\n",
      "val_loss: 0.08727805956732482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  70%|███████   | 14/20 [05:40<02:30, 25.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.66999816894531%\n",
      "val_loss: 0.09041420766152442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  75%|███████▌  | 15/20 [06:06<02:07, 25.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.63999938964844%\n",
      "val_loss: 0.09022549306973815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  80%|████████  | 16/20 [06:34<01:44, 26.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.5999984741211%\n",
      "val_loss: 0.09096389613114297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  85%|████████▌ | 17/20 [06:58<01:16, 25.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.55999755859375%\n",
      "val_loss: 0.09108555503189564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  90%|█████████ | 18/20 [07:21<00:49, 24.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.53999328613281%\n",
      "val_loss: 0.09169882838614285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  95%|█████████▌| 19/20 [07:46<00:24, 24.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.53999328613281%\n",
      "val_loss: 0.093390446389094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 20/20 [08:10<00:00, 24.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of server: 97.55999755859375%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "server = ServerMLP(model=model_dovera, test_loader=test_loader)\n",
    "\n",
    "user_list = []\n",
    "\n",
    "# Create users\n",
    "for i in range(3):\n",
    "    user_i = UserMLP(train_loader=train_loader_list[i], model=model_dovera, user_id=i, local_epochs=5)\n",
    "    user_list.append(user_i)\n",
    "\n",
    "\n",
    "\n",
    "for _ in tqdm(range(20), desc=f\"Progress\"):\n",
    "    # Distribute initial model to users\n",
    "    server.distribute_model(user_list)\n",
    "    \n",
    "    # Sub-sample users\n",
    "    sub_user_list = random.sample(user_list, int(1 * 3))\n",
    "\n",
    "    # Check the sub-sampled user and train model\n",
    "    users_loss = 0.0\n",
    "    for user in sub_user_list:\n",
    "        user_loss = user.user_train()\n",
    "        users_loss += user_loss\n",
    "    # Aggregate weights on server\n",
    "    server.aggregate_weights(sub_user_list)\n",
    "\n",
    "    # Calulate avg loss on selected users\n",
    "    train_loss =  users_loss / len(sub_user_list)    \n",
    "    val_loss = server.model_eval()\n",
    "\n",
    "    # wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss})\n",
    "    print(f'Test accuracy of server: {server.compute_accuracy()}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "resnet = torchvision.models.resnet50()\n",
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2048, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for child in resnet.children():\n",
    "        if isinstance(child, nn.Linear):\n",
    "            print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2Model.from_pretrained('gpt2')\n",
    "for child in model.children():\n",
    "        if isinstance(child, nn.Linear):\n",
    "            print(child)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
